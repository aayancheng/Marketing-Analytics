{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 01 — Exploratory Data Analysis: UCI Online Retail II\n",
    "\n",
    "**Dataset:** UCI Online Retail II (id=502)  \n",
    "**Source:** UK-based online gift retailer, transactions 01/12/2009 – 09/12/2011  \n",
    "**Goal:** Profile the raw data, confirm key statistics, and understand purchase-hour distributions for the email send-time optimization pipeline.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\n\n# Paths\nimport os\nPROJECT_ROOT = os.path.abspath(os.path.join(os.getcwd(), '..'))\nRAW_DIR = os.path.join(PROJECT_ROOT, 'data', 'raw')\nCSV_PATH = os.path.join(RAW_DIR, 'online_retail_ii.csv')\n\nprint(f'Project root: {PROJECT_ROOT}')\nprint(f'CSV path: {CSV_PATH}')\nprint(f'File exists: {os.path.exists(CSV_PATH)}')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Raw Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(CSV_PATH, parse_dates=['InvoiceDate'])\n",
    "print(f'Total rows: {len(df):,}')\n",
    "print(f'Columns: {df.columns.tolist()}')\n",
    "print(f'Date range: {df[\"InvoiceDate\"].min()} — {df[\"InvoiceDate\"].max()}')\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data Profile: Nulls and Duplicates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== NULL COUNTS ===')\n",
    "null_counts = df.isnull().sum()\n",
    "null_pct = (df.isnull().sum() / len(df) * 100).round(2)\n",
    "null_summary = pd.DataFrame({'null_count': null_counts, 'null_pct': null_pct})\n",
    "print(null_summary)\n",
    "\n",
    "print(f'\\n=== DUPLICATES ===')\n",
    "n_dups = df.duplicated().sum()\n",
    "print(f'Duplicate rows: {n_dups:,} ({n_dups/len(df)*100:.2f}%)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Row Count Confirmation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(f'Total row count: {len(df):,}')\nprint(f'Expected ~1,067,371 — Match: {abs(len(df) - 1_067_371) < 100}')\n\n# Sheet breakdown\nyr_2009_2010 = df[df['InvoiceDate'].dt.year.isin([2009, 2010])]\nyr_2010_2011 = df[df['InvoiceDate'].dt.year.isin([2010, 2011])]\nprint(f'\\nRows by year:')\nprint(df['InvoiceDate'].dt.year.value_counts().sort_index())\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Customer ID Analysis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_unique_customers = df['Customer ID'].nunique()\n",
    "n_null_customers = df['Customer ID'].isna().sum()\n",
    "\n",
    "print(f'Unique CustomerIDs (before filtering nulls): {n_unique_customers:,}')\n",
    "print(f'Expected ~5,900 — in range: {5_700 < n_unique_customers < 6_100}')\n",
    "print(f'Rows with null CustomerID: {n_null_customers:,} ({n_null_customers/len(df)*100:.1f}%)')\n",
    "\n",
    "# After filtering\n",
    "df_with_cust = df.dropna(subset=['Customer ID'])\n",
    "print(f'\\nRows after dropping null CustomerID: {len(df_with_cust):,}')\n",
    "print(f'Unique CustomerIDs after filter: {df_with_cust[\"Customer ID\"].nunique():,}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Country Distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_pct = (df['Country'] == 'United Kingdom').mean() * 100\n",
    "print(f'UK row proportion: {uk_pct:.1f}%')\n",
    "print(f'Expected ~90% UK — within range: {85 < uk_pct < 95}')\n",
    "\n",
    "print('\\n=== TOP 15 COUNTRIES BY TRANSACTION COUNT ===')\n",
    "top_countries = df['Country'].value_counts().head(15)\n",
    "print(top_countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Top countries by unique customer count\n",
    "print('=== TOP 15 COUNTRIES BY UNIQUE CUSTOMER COUNT ===')\n",
    "top_countries_cust = (\n",
    "    df_with_cust.groupby('Country')['Customer ID']\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(15)\n",
    ")\n",
    "print(top_countries_cust)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "top_countries_cust.plot(kind='bar', ax=ax, color='steelblue', edgecolor='white')\n",
    "ax.set_title('Top 15 Countries by Unique Customer Count', fontsize=14)\n",
    "ax.set_xlabel('Country')\n",
    "ax.set_ylabel('Unique Customers')\n",
    "ax.tick_params(axis='x', rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Cancellation Rate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancellations = df['Invoice'].astype(str).str.startswith('C')\n",
    "cancel_rate = cancellations.mean() * 100\n",
    "print(f'Cancellation rows: {cancellations.sum():,}')\n",
    "print(f'Cancellation rate: {cancel_rate:.2f}%')\n",
    "\n",
    "# By year\n",
    "df['is_cancelled'] = cancellations\n",
    "print('\\nCancellations by year:')\n",
    "print(df.groupby(df['InvoiceDate'].dt.year)['is_cancelled'].agg(['sum', 'mean'])\n",
    "      .rename(columns={'sum': 'cancel_count', 'mean': 'cancel_rate'}))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Hour and Day-of-Week Distributions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['InvoiceDate'].dt.hour\n",
    "df['day_of_week'] = df['InvoiceDate'].dt.day_name()\n",
    "\n",
    "print('=== TRANSACTION COUNT BY HOUR ===')\n",
    "hour_counts = df.groupby('hour').size()\n",
    "print(hour_counts)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Hour distribution\n",
    "hour_counts.plot(kind='bar', ax=axes[0], color='steelblue', edgecolor='white')\n",
    "axes[0].set_title('Transactions by Hour of Day', fontsize=13)\n",
    "axes[0].set_xlabel('Hour')\n",
    "axes[0].set_ylabel('Transaction Count')\n",
    "axes[0].tick_params(axis='x', rotation=0)\n",
    "\n",
    "# Day of week distribution\n",
    "dow_order = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "dow_counts = df.groupby('day_of_week').size().reindex(dow_order)\n",
    "dow_counts.plot(kind='bar', ax=axes[1], color='coral', edgecolor='white')\n",
    "axes[1].set_title('Transactions by Day of Week', fontsize=13)\n",
    "axes[1].set_xlabel('Day')\n",
    "axes[1].set_ylabel('Transaction Count')\n",
    "axes[1].tick_params(axis='x', rotation=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Modal Purchase Hour Distribution Across Customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Compute each customer's modal (most common) purchase hour\n# Re-derive df_with_cust now that 'hour' column has been added to df\ndf_with_cust_h = df.dropna(subset=['Customer ID'])\n\ncustomer_modal_hour = (\n    df_with_cust_h.groupby('Customer ID')['hour']\n    .agg(lambda x: x.mode().iloc[0])\n    .reset_index()\n    .rename(columns={'hour': 'modal_hour'})\n)\n\nprint(f'Customers with modal hour computed: {len(customer_modal_hour):,}')\nprint('\\nModal hour distribution across customers:')\nmodal_dist = customer_modal_hour['modal_hour'].value_counts().sort_index()\nprint(modal_dist)\n\nfig, ax = plt.subplots(figsize=(12, 5))\nmodal_dist.plot(kind='bar', ax=ax, color='mediumseagreen', edgecolor='white')\nax.set_title('Distribution of Modal Purchase Hour Across Customers', fontsize=14)\nax.set_xlabel('Hour of Day (modal purchase hour per customer)')\nax.set_ylabel('Number of Customers')\nax.tick_params(axis='x', rotation=0)\nplt.tight_layout()\nplt.show()\n\nmost_common_modal_hour = customer_modal_hour['modal_hour'].mode().iloc[0]\nprint(f'\\nMost common modal purchase hour: {most_common_modal_hour}:00')\n"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('=== EDA SUMMARY ===')\n",
    "print(f'Total rows:                 {len(df):>12,}')\n",
    "print(f'Unique CustomerIDs (raw):   {df[\"Customer ID\"].nunique():>12,}')\n",
    "print(f'Null CustomerID rows:       {df[\"Customer ID\"].isna().sum():>12,}')\n",
    "print(f'Duplicate rows:             {df.duplicated().sum():>12,}')\n",
    "print(f'Cancellation rate:          {cancel_rate:>11.2f}%')\n",
    "print(f'UK transaction proportion:  {uk_pct:>11.1f}%')\n",
    "print(f'Date range start:           {df[\"InvoiceDate\"].min()}')\n",
    "print(f'Date range end:             {df[\"InvoiceDate\"].max()}')\n",
    "print(f'Peak transaction hour:      {hour_counts.idxmax()}:00')\n",
    "print(f'Most common modal hour:     {most_common_modal_hour}:00')\n",
    "print(f'Number of countries:        {df[\"Country\"].nunique():>12,}')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}